{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2616d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://pop-os:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Titanic Data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d00b587a710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local') \\\n",
    "    .appName('Titanic Data') \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-Djava.security.manager=allow\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf92fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "         .format('csv')\n",
    "         .option('header', 'true')\n",
    "         .load('./titanic/train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc39358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male| 22|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female| 38|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female| 26|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "+-----------+--------+------+--------------------+------+---+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9d96feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf6ad944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+------+------+----+-------+--------+\n",
      "|     0.0|   3.0|  male|22.0|   7.25|       S|\n",
      "|     1.0|   1.0|female|38.0|71.2833|       C|\n",
      "|     1.0|   3.0|female|26.0|  7.925|       S|\n",
      "+--------+------+------+----+-------+--------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "dataset = df.select(col('Survived').cast('float'),\n",
    "                    col('Pclass').cast('float'),\n",
    "                    col('Sex'),\n",
    "                    col('Age').cast('float'),\n",
    "                    col('Fare').cast('float'),\n",
    "                    col('Embarked')\n",
    "                   )\n",
    "\n",
    "dataset.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699d909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace('?', None).dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73ffb463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 562\n",
      "Number of test samples: 150\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "(train_df, test_df) = dataset.randomSplit([0.8, 0.2], 11)\n",
    "print('Number of train samples: ' + str(train_df.count()))\n",
    "print('Number of test samples: ' + str(test_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2793001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex_indexer = StringIndexer(inputCol='Sex', outputCol='Gender')\n",
    "Embark_indexer = StringIndexer(inputCol='Embarked', outputCol='Boarded')\n",
    "\n",
    "inputCols = ['Pclass', 'Age', 'Fare', 'Gender', 'Boarded']\n",
    "outputCol = 'features'\n",
    "vector_assembler = VectorAssembler(inputCols=inputCols, outputCol=outputCol)\n",
    "\n",
    "dt_model = RandomForestClassifier(labelCol='Survived', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e4e55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+---------------------------------------+----------+\n",
      "|Survived|Pclass|Sex |Age |Fare   |Embarked|Gender|Boarded|features                           |rawPrediction                         |probability                            |prediction|\n",
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+---------------------------------------+----------+\n",
      "|0.0     |1.0   |male|19.0|263.0  |S       |0.0   |0.0    |[1.0,19.0,263.0,0.0,0.0]           |[10.607023888317736,9.392976111682268]|[0.5303511944158867,0.4696488055841133]|0.0       |\n",
      "|0.0     |1.0   |male|21.0|77.2875|S       |0.0   |0.0    |[1.0,21.0,77.2874984741211,0.0,0.0]|[8.843144678097058,11.15685532190294] |[0.4421572339048529,0.557842766095147] |1.0       |\n",
      "|0.0     |1.0   |male|28.0|82.1708|C       |0.0   |1.0    |[1.0,28.0,82.1707992553711,0.0,1.0]|[9.186512439860907,10.813487560139093]|[0.4593256219930454,0.5406743780069546]|1.0       |\n",
      "|0.0     |1.0   |male|29.0|30.0   |S       |0.0   |0.0    |[1.0,29.0,30.0,0.0,0.0]            |[9.45214867771657,10.54785132228343]  |[0.4726074338858285,0.5273925661141715]|1.0       |\n",
      "|0.0     |1.0   |male|29.0|66.6   |S       |0.0   |0.0    |[1.0,29.0,66.5999984741211,0.0,0.0]|[7.49719864189857,12.502801358101431] |[0.3748599320949285,0.6251400679050716]|1.0       |\n",
      "+--------+------+----+----+-------+--------+------+-------+-----------------------------------+--------------------------------------+---------------------------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[Sex_indexer, Embark_indexer, vector_assembler, dt_model])\n",
    "\n",
    "final_pipeline = pipeline.fit(train_df)\n",
    "\n",
    "test_predictions_from_pipeline = final_pipeline.transform(test_df)\n",
    "\n",
    "test_predictions_from_pipeline.show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
